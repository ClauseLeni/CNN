{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Serialization\n",
    "using Flux\n",
    "using OneHotArrays\n",
    "using Statistics\n",
    "using StatsBase\n",
    "using InvertedIndices\n",
    "using Plots\n",
    "using CircularArrays\n",
    "using CSV, DataFrames\n",
    "using StatsPlots\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "using Random\n",
    "Random.seed!(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty arrays to store data and corresponding target labels\n",
    "alldata = Float32[]  # Array to store data\n",
    "alltargets = Bool[]  # Array to store target labels (true/false)\n",
    "\n",
    "footprint_files = filter!(x -> endswith(x, \".bin\"), readdir(\"fiveprime_footprints\", join=true))\n",
    "numfootprints = 0\n",
    "for ff in footprint_files\n",
    "    # Deserialize data from file \"footprints/i.bin\" and store it in the 'matrix' variable\n",
    "    matrix = deserialize(ff)\n",
    "    \n",
    "    # Append the deserialized data (matrix) to the 'alldata' array\n",
    "    append!(alldata, matrix)\n",
    "    \n",
    "    # Append the label 'true' to the 'alltargets' array to indicate that this data is a 'footprint'\n",
    "    append!(alltargets, true)\n",
    "\n",
    "    numfootprints += 1\n",
    "end\n",
    "numfootprints\n",
    "\n",
    "background_files = filter!(x -> endswith(x, \".bin\"), readdir(\"fiveprime_backgrounds\", join=true))\n",
    "numbackgrounds = 0\n",
    "for bg in background_files\n",
    "    matrix = deserialize(bg)\n",
    "    append!(alldata, matrix)\n",
    "    append!(alltargets, false)\n",
    "\n",
    "    numbackgrounds += 1\n",
    "end\n",
    "numfootprints, numbackgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model using Chain composition\n",
    "model = Chain(\n",
    "    # Convolutional layer with a 3x3 kernel size, 1 input channel, and 3 output channels, followed by ReLU activation\n",
    "    # Padding can be used to ensure that the spatial dimensions of the output feature maps are the same as the input image. In this case, pad = SamePad() is used.\n",
    "    Conv((3,3), 1 => 1, relu),\n",
    "    # Maxpooling layer with a 3x3 pooling window\n",
    "    x -> maxpool(x, (16,1)),\n",
    "    # Reshape layer to flatten the output tensor\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    # Fully connected dense layer with input size calculated from the previous layer output dimensions and 2 output neurons\n",
    "    Dense(3, 2),\n",
    "    # Softmax activation function to compute class probabilities\n",
    "    softmax\n",
    ")\n",
    "\n",
    "# Setup the Adam optimizer with a learning rate of 0.01 and associate it with the model\n",
    "optim = Flux.setup(Flux.Adam(0.01), model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random indices to select test data from 'alldata'\n",
    "testidxs = sort!(sample(1:100000, 10000, replace = false))\n",
    "\n",
    "# Define ranges of indices corresponding to the selected test data\n",
    "testranges = reduce(vcat, [collect(i*150-149:i*150) for i in testidxs])\n",
    "\n",
    "# Extract test data from 'alldata' using the defined ranges\n",
    "testdata = alldata[testranges]\n",
    "\n",
    "# Reshape test data to match the required format for model input\n",
    "testdata = reshape(testdata, 50, 3, 1, 10000)\n",
    "\n",
    "# Create one-hot encoded labels for test targets based on 'alltargets' using the selected test indices\n",
    "testtargets = onehotbatch(alltargets[testidxs], [true, false])\n",
    "\n",
    "# Extract training data by excluding the test data ranges from 'alldata'\n",
    "trainingdata = alldata[Not(testranges)]\n",
    "\n",
    "# Reshape training data to match the required format for model input\n",
    "trainingdata = reshape(trainingdata, 50, 3, 1, 90000)\n",
    "\n",
    "# Create one-hot encoded labels for training targets based on 'alltargets' excluding the test indices\n",
    "trainingtargets = onehotbatch(alltargets[Not(testidxs)], [true, false])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader object by passing training data and targets as a tuple,\n",
    "# setting the batch size to 20, and shuffling the data during training\n",
    "loader = Flux.DataLoader((trainingdata, trainingtargets), batchsize=20, shuffle=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#println(\"Footprints in test set: \", count(i -> i, alltargets[testidxs]))\n",
    "println(\"Footprints in training set: \", count(i -> i, alltargets[Not(testidxs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function trainmodel!(model, loader)\n",
    "    # Create an empty array to store losses during training\n",
    "    meanlosses = Float64[]\n",
    "\n",
    "    # Training loop, using the whole data set 1000 times:\n",
    "    for epoch in 1:100\n",
    "        losses = Float64[]\n",
    "        for (x, y) in loader\n",
    "            loss, grads = Flux.withgradient(model) do m\n",
    "                # Evaluate model and loss inside gradient context:\n",
    "                y_hat = m(x)\n",
    "                Flux.crossentropy(y_hat, y)\n",
    "            end\n",
    "            Flux.update!(optim, model, grads[1])\n",
    "            push!(losses, loss)  # logging, outside gradient context\n",
    "        end\n",
    "        push!(meanlosses, mean(losses))\n",
    "    end\n",
    "    meanlosses\n",
    "end\n",
    "\n",
    "losses = trainmodel!(model, loader)\n",
    "plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function testmodel(testdata, testtargets)\n",
    "    # Pass the test data through the model to get predictions\n",
    "    out = model(testdata)\n",
    "\n",
    "    # Initialize counters for successful and failed predictions\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    # Iterate over each sample in the test dataset\n",
    "    for i in 1:size(testtargets, 2)\n",
    "        # Check if the predicted class matches the true class for each sample\n",
    "        if out[1, i] > 0.5 && testtargets[1, i] > 0.5\n",
    "            tp += 1\n",
    "        elseif out[1, i] > 0.5 && testtargets[1, i] <= 0.5\n",
    "            fp += 1\n",
    "        elseif out[1, i] <= 0.5 && testtargets[1, i] > 0.5\n",
    "            fn += 1\n",
    "        elseif out[1, i] <= 0.5 && testtargets[1, i] <= 0.5\n",
    "            tn += 1\n",
    "        else\n",
    "            println(out[1, i], \"\\t\", testtargets[1, i])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Return the counts of successful and failed predictions\n",
    "    tp, tn, fp, fn\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, tn, fp, fn = testmodel(testdata, testtargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Serialization, CSV, DataFrames, CircularArrays\n",
    "\n",
    "# --- Load genome annotations and build structural masks ---\n",
    "Atgff = CSV.File(\"AP000423.gff\"; comment = \"#\",\n",
    "    header = [\"accession\", \"software\", \"feature\", \"start\", \"stop\", \"score\", \"strand\", \"phase\", \"attributes\"]\n",
    ") |> DataFrame\n",
    "\n",
    "genome_length = first(Atgff[Atgff.feature .== \"region\", :stop])\n",
    "rc(x::Real) = genome_length - x + 1\n",
    "\n",
    "# Identify structural RNA features\n",
    "structural = filter(x -> x.feature âˆˆ [\"tRNA\", \"rRNA\"], Atgff)\n",
    "\n",
    "# Build boolean masks\n",
    "mask_fwd = falses(genome_length)\n",
    "mask_rev = falses(genome_length)\n",
    "for row in eachrow(structural)\n",
    "    mask_fwd[row.start:row.stop] .= true\n",
    "    mask_rev[rc(row.stop):rc(row.start)] .= true\n",
    "end\n",
    "\n",
    "# --- Masking helper ---\n",
    "function apply_mask!(data, mask)\n",
    "    data[mask] .= 0.0\n",
    "    return data\n",
    "end\n",
    "\n",
    "# --- Load & mask datasets before normalization ---\n",
    "fwd_srna = apply_mask!(deserialize(\"srna_fwd.bin\"), mask_fwd)\n",
    "rev_srna = apply_mask!(deserialize(\"srna_rev.bin\"), mask_rev)\n",
    "\n",
    "fwd_fiveprime = apply_mask!(deserialize(\"ligated_vs_untreated.fwd.five.bin\"), mask_fwd)\n",
    "rev_fiveprime = apply_mask!(deserialize(\"ligated_vs_untreated.rev.five.bin\"), mask_rev)\n",
    "\n",
    "fwd_conservation = apply_mask!(CircularVector(deserialize(\"arabidopsis_conservation.bin\")), mask_fwd)\n",
    "rev_conservation = apply_mask!(reverse(fwd_conservation), mask_rev)\n",
    "\n",
    "# --- Normalization ---\n",
    "function log_normalise(fwd_data, rev_data)\n",
    "    log_fwd_data = log.(fwd_data .+ 1)\n",
    "    log_rev_data = log.(rev_data .+ 1)\n",
    "    minval = min(minimum(log_fwd_data), minimum(log_rev_data))\n",
    "    maxval = max(maximum(log_fwd_data), maximum(log_rev_data))\n",
    "    log_fwd_data .= (log_fwd_data .- minval) ./ maxval\n",
    "    log_rev_data .= (log_rev_data .- minval) ./ maxval\n",
    "    return log_fwd_data, log_rev_data\n",
    "end\n",
    "\n",
    "fwd_conservation, rev_conservation = log_normalise(fwd_conservation, rev_conservation)\n",
    "fwd_srna, rev_srna = log_normalise(fwd_srna, rev_srna)\n",
    "fwd_fiveprime, rev_fiveprime = log_normalise(fwd_fiveprime, rev_fiveprime)\n",
    "\n",
    "# --- Verify that masking worked ---\n",
    "for (name, data) in [\n",
    "    (\"Conservation\", fwd_conservation),\n",
    "    (\"sRNA\", fwd_srna),\n",
    "    (\"fiveprime\", fwd_fiveprime)\n",
    "]\n",
    "    is_zero = all(data[104691:107500] .== 0.0)\n",
    "    println(rpad(name, 12), \": \", is_zero)\n",
    "end\n",
    "\n",
    "# --- Window extraction ---\n",
    "function datawindow!(datablock::Vector{Float32}, strand::String, p::Int, w::Int)\n",
    "    if strand == \"+\"\n",
    "        datablock[1:w]         .= fwd_conservation[p:p+w-1]\n",
    "        datablock[w+1:2*w]     .= fwd_srna[p:p+w-1]\n",
    "        datablock[2*w+1:3*w]   .= fwd_fiveprime[p:p+w-1]\n",
    "    else\n",
    "        datablock[1:w]         .= rev_conservation[p:p+w-1]\n",
    "        datablock[w+1:2*w]     .= rev_srna[p:p+w-1]\n",
    "        datablock[2*w+1:3*w]   .= rev_fiveprime[p:p+w-1]\n",
    "    end\n",
    "    return datablock\n",
    "end\n",
    "\n",
    "# --- Safe helper ---\n",
    "window_inbounds(p::Int, w::Int, L::Int) = (p >= 1) && (p + w - 1 <= L)\n",
    "\n",
    "# --- Zero prediction template ---\n",
    "const ZERO_PRED = Float32[0.0, 1.0]\n",
    "\n",
    "# --- Model inference with bounds & mask protection ---\n",
    "window = 50\n",
    "datablock = Vector{Float32}(undef, window * 3)\n",
    "\n",
    "L = length(fwd_conservation)\n",
    "fwd_predictions = Vector{Vector{Float32}}(undef, L)\n",
    "\n",
    "for position in 1:L\n",
    "    if mask_fwd[position] || !window_inbounds(position, window, L)\n",
    "        fwd_predictions[position] = ZERO_PRED\n",
    "        continue\n",
    "    end\n",
    "    datablock = datawindow!(datablock, \"+\", position, window)\n",
    "    pred = model(reshape(datablock, window, 3, 1, 1))\n",
    "    fwd_predictions[position] = vec(Array(pred))\n",
    "end\n",
    "\n",
    "Lr = length(rev_conservation)\n",
    "rev_predictions = Vector{Vector{Float32}}(undef, Lr)\n",
    "\n",
    "for position in 1:Lr\n",
    "    if mask_rev[position] || !window_inbounds(position, window, Lr)\n",
    "        rev_predictions[position] = ZERO_PRED\n",
    "        continue\n",
    "    end\n",
    "    datablock = datawindow!(datablock, \"-\", position, window)\n",
    "    pred = model(reshape(datablock, window, 3, 1, 1))\n",
    "    rev_predictions[position] = vec(Array(pred))\n",
    "end\n",
    "\n",
    "serialize(\"fiveprime_3x3_16_3.predictions\", (fwd_predictions, rev_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
